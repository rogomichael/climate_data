{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipping The netcdf files by shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import some libraries that we need. \n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import regionmask \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "#Getting the currecnt working directory\n",
    "pwd = os.getcwd()\n",
    "os.chdir(pwd)\n",
    "print(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = \"/Users/michaelrogo/software/cli_he_code/hacked/NUTS_RG_20M_2021_4326/NUTS_RG_20M_2021_4326.shp\"\n",
    "countries = gpd.read_file(shapefile, header='None')\n",
    "querry = 3\n",
    "countries = countries[countries['LEVL_CODE'] == querry]\n",
    "#countries['NUTS_ID'].to_csv('file.csv', header=False)\n",
    "\n",
    "\n",
    "with open('codes.csv', 'a') as file:\n",
    "        if os.path.getsize('codes.csv') == 0:\n",
    "            file.write('ID_NO,NUTS_ID\\n')\n",
    "            countries['NUTS_ID'].to_csv(file, header=False, index=True)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "df = pd.read_csv(\"codes.csv\")\n",
    "print(len(df))\n",
    "my_dict = dict(zip(df['ID_NO'], df['NUTS_ID']))\n",
    "#my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "#  Let's plot the area presented by shape file\n",
    "#----------------------------------------\n",
    "#fig, ax = plt.subplots(figsize=(16, 10))\n",
    "#countries.plot(ax=ax, column='NUTS_ID')\n",
    "#countries.head()['NUTS_ID']\n",
    "#.to_pandas().to_csv(\"nuts_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comes the .nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##----------------------------------------\n",
    "#Read the Netcdf file \n",
    "#The following command is for data with single variables of the nc file masked to the shape file\n",
    "#To reproduce the results, please create the respective paths manually on disk and not by the code!! \n",
    "#One can choose desired paths\n",
    "#RESULTS\n",
    "# We get a bunch of csv files for each region with values. We use the code in the next cell to process them into one \n",
    "#huge file. But even at this level, we can get some insights\n",
    "##----------------------------------------\n",
    "#print(pwd)\n",
    "path = '/Users/michaelrogo/software/cli_he_code/hacked/' #path where we have the nc file\n",
    "\n",
    "#dest = '/Users/michaelrogo/software/cli_he_code/hacked/max_temp/max_files' #path where we dump nc files (not used at the moment) \n",
    "#The code first identifies the coordinates of regions in the nc file and mask them with the shape file. \n",
    "#We then use the mask to extract the values of interest (looped over every region of interest). \n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    f = os.path.join(path,filename)\n",
    "    if f.endswith('.nc'):\n",
    "        year = f[-7:-3]\n",
    "        \n",
    "        #read nc file and assign lons and lats of interest\n",
    "        d = xr.open_mfdataset(f, chunks = {'time': 10})\n",
    "        d = d.assign_coords(longitude=(((d.longitude + 180) % 360) - 180)).sortby('longitude')\n",
    "        #print(\"\\n ---------------\\nShowing NetCDF4 for {}.....\\n ---------------\\n\".format(f), d)\n",
    "        #CALCULATE MASK\n",
    "        nuts = countries\n",
    "        #names = list(nuts.NUTS_ID)\n",
    "        #len(names)\n",
    "        \n",
    "        #mask these coordinates to each region. The length of the nuts region is 1514 (from the shape file) \n",
    "        #The line is long and broken by '\\' symbol\n",
    "        nuts_mask_poly = regionmask.Regions(name = 'nuts_mask', numbers = list(range(0,1514))\\\n",
    "        , names = list(nuts.NUTS_ID), abbrevs = list(nuts.NUTS_ID)\\\n",
    "        , outlines = list(nuts.geometry.values[i] for i in range(0,1514)))\n",
    "\n",
    "        print(\"--------------------------------\\n\\\n",
    "                Masking {}...\\n--------------------------------\\n\\\n",
    "                \".format(f),nuts_mask_poly)\n",
    "        mask = nuts_mask_poly.mask(d.isel(time=0), lat_name='latitude', lon_name='longitude')\n",
    "        \n",
    "        #Here we read the IDs of each region in a loop to extract point data. As is clear, the loop tries\n",
    "        #to skip missing values which are problematic when we have NaN within the values extracted (basically\n",
    "        #empty NUTS regions)\n",
    "        nuts_ids = []\n",
    "        for i in my_dict:\n",
    "            ID_REGION = i\n",
    "            nuts_ids.append(ID_REGION)\n",
    "            lat = mask.latitude.values\n",
    "            lon = mask.longitude.values\n",
    "            sel_mask = mask.where(mask == ID_REGION).values\n",
    "            #print(sel_mask)\n",
    "            a = []\n",
    "            id_lon = lon[np.where(~np.all(np.isnan(sel_mask), axis=0))]\n",
    "            id_lat = lat[np.where(~np.all(np.isnan(sel_mask), axis=1))]\n",
    "            if len(id_lon) | len(id_lat) :\n",
    "                #print(ID_REGION, \"\\t lon-->\", id_lon)\n",
    "                #print(ID_REGION, \"\\t lat-->\", id_lat)\n",
    "                print(\"\\n\")\n",
    "                out_sel = d.sel(latitude = slice(id_lat[0], id_lat[-1]), longitude = slice(id_lon[0], id_lon[-1])).compute().where(mask == ID_REGION)\n",
    "                #print(out_sel) \n",
    "                print(\"\\n------Extracting Temp Data for.......\",ID_REGION)\n",
    "                x = out_sel.groupby('time').mean(...)\n",
    "                tg_id = nuts.NUTS_ID[ID_REGION]\n",
    "                \n",
    "                x.tg.to_pandas().to_csv('{}_{}.csv'.format(tg_id, year), header= ['{}'.format(tg_id)])\n",
    "                df = pd.read_csv(\"{}_{}.csv\".format(tg_id, year))\n",
    "                #df.to_excel(\"{}.xlsx\".format(tg_id))\n",
    "                df['time'] = pd.to_datetime(df['time'])\n",
    "                monthly_min = df.groupby(df.time.dt.month)['{}'.format(tg_id)]\n",
    "                #----------MAX_TEMP-----------#\n",
    "                print(\"\\n------MAX TEMP--------\")\n",
    "                max_temp = monthly_min.max()\n",
    "                max_tempdf = pd.DataFrame(max_temp)\n",
    "                print(max_tempdf)\n",
    "                max_tempdf.to_csv('{}_maxtemp_{}.csv'.format(tg_id, year))\n",
    "                #----------MIN_TEMP-----------#\n",
    "                print(\"\\n------MIN TEMP--------\")\n",
    "                min_temp = monthly_min.min()\n",
    "                min_tempdf = pd.DataFrame(min_temp)\n",
    "                print(min_tempdf)\n",
    "                min_tempdf.to_csv('{}_mintemp_{}.csv'.format(tg_id, year))\n",
    "                #----------MEAN_TEMP-----------#\n",
    "                print(\"\\n------MEAN TEMP--------\")\n",
    "                mean_temp = monthly_min.mean()\n",
    "                mean_tempdf = pd.DataFrame(mean_temp)\n",
    "                print(mean_tempdf)\n",
    "                mean_tempdf.to_csv('{}_meantemp_{}.csv'.format(tg_id, year))\n",
    "            else:\n",
    "                pass\n",
    "        #print(out_sel)\n",
    "        print(\"\\n------------------------------------------------------------------------------\")\n",
    "        print(\"\\n DONE PROCESSING..\")\n",
    "        print(\"\\n------------------------------------------------------------------------------\")\n",
    "#delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------#\n",
    "#----------------PROCESS 2019 MIN_TEST TEMPERATURES-------------------#\n",
    "#-----------------------------------------------------------------#\n",
    "\n",
    "#The obtained csv files above was copied into different folders. I.e max, mean, and min for each year. Here we \n",
    "#use 2019 as an example year\n",
    "#So this code cds into the dir with the min files and writes the final output there. \n",
    "#One needs to install csvkit --- pip install csvkit ---- for this code to work\n",
    "#We use cskit for file merging. But since it is a command line app, we load it's commands using Sultan \n",
    "#library within python. In other words, we are calling bash commands within python\n",
    "#of course other imported libraries are also installed. \n",
    "#The procedure could be inefficient but it works in a clever way.\n",
    "#ignore the codes below this cell\n",
    "\n",
    "from sultan.api import Sultan\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "#Function to convert csv_files list to string\n",
    "def listToString(s):\n",
    "    # initialize an empty string\n",
    "    str1 = \" \"\n",
    "    # return string \n",
    "    return (str1.join(s))\n",
    "\n",
    "min_path = '/Users/michaelrogo/software/cli_he_code/hacked/processed/temp_2019/min/'\n",
    "os.chdir(min_path)\n",
    "pwd = min_path\n",
    "#print(pwd)\n",
    "#Run bash code to merge files\n",
    "with Sultan.load() as sultan:\n",
    "    items = [f for f in os.listdir(path) if os.path.isfile( os.path.join(path, f))\\\n",
    "             if f.endswith('_2019.csv')]\n",
    "    items.sort()\n",
    "    item = items[0]\n",
    "    rest__of_files = listToString(items[1:])\n",
    "    sultan.csvjoin('-c time {} {} --left > merged.csv'.format(item, rest__of_files)).run()\n",
    "    #(\"csvjoin -c time AL011_mintemp_2019.csv *.csv --left > merged_bash.csv\")\n",
    "print(\"\\nDONE MERGING FILES.........\\n\")\n",
    "\n",
    "#Create a final file using pandas\n",
    "\n",
    "print(\"CREATING a final file.....\")\n",
    "df = pd.read_csv('merged.csv')\n",
    "#print(df)\n",
    "month = df['time'] - 1\n",
    "q = month // 3 + 1\n",
    "q = pd.DataFrame(q)\n",
    "df = df.join(q, lsuffix='_months', rsuffix='_quater')\n",
    "#print(df.loc[df['time_quater'] == 1])\n",
    "#print(\"------------------------------------------\\n\")\n",
    "maxTemp = df.loc[df['time_quater'] == 1].min()\n",
    "results = pd.DataFrame(maxTemp)\n",
    "results.to_csv('min_mergedTemps.csv')\n",
    "print(\"-------DONE PROCESSING----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Now apply the mask on the gridded dataset d.\n",
    "#Select only first timestep to speed up the process\n",
    "#Zoom only on the European continent\n",
    "print(\"Masking takes a while, please wait........\")\n",
    "mask = nuts_mask_poly.mask(d.isel(time=0), lat_name='latitude', lon_name='longitude')\n",
    "#mask\n",
    "print(\"Mask done\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Plot the figure \n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.axes()\n",
    "mask.plot(ax = ax)\n",
    "nuts.plot(ax = ax, alpha = 0.8, facecolor = 'none', lw = 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract time-series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#countries = countries[countries['LEVL_CODE'] == querry]\n",
    "#nuts.NUTS_ID\n",
    "#print(nuts[nuts['NUTS_ID'] == ID_REGION])\n",
    "\n",
    "nuts_ids = []\n",
    "for i in my_dict:\n",
    "    ID_REGION = i\n",
    "    #print(ID_REGION)\n",
    "    nuts_ids.append(ID_REGION)\n",
    "    #print(nuts_ids)\n",
    "#print(nuts.NUTS_ID[ID_REGION])\n",
    "\n",
    "#print(type(my_dict))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nuts_ids = []\n",
    "for i in my_dict:\n",
    "    ID_REGION = i\n",
    "    nuts_ids.append(ID_REGION)\n",
    "    lat = mask.latitude.values\n",
    "    lon = mask.longitude.values\n",
    "    sel_mask = mask.where(mask == ID_REGION).values\n",
    "    #print(sel_mask)\n",
    "    a = []\n",
    "    id_lon = lon[np.where(~np.all(np.isnan(sel_mask), axis=0))]\n",
    "    id_lat = lat[np.where(~np.all(np.isnan(sel_mask), axis=1))]\n",
    "    if len(id_lon) | len(id_lat) :\n",
    "        #print(ID_REGION, \"\\t lon-->\", id_lon)\n",
    "        #print(ID_REGION, \"\\t lat-->\", id_lat)\n",
    "        print(\"\\n\")\n",
    "        out_sel = d.sel(latitude = slice(id_lat[0], id_lat[-1]), longitude = slice(id_lon[0], id_lon[-1])).compute().where(mask == ID_REGION)\n",
    "        #print(out_sel) \n",
    "        print(\"\\n------Extracting Temp Data for.......\",ID_REGION)\n",
    "        x = out_sel.groupby('time').mean(...)\n",
    "        tg_id = nuts.NUTS_ID[ID_REGION]\n",
    "        x.tg.to_pandas().to_csv('{}_{}.csv'.format(tg_id, year), header= ['{}'.format(tg_id)])\n",
    "        df = pd.read_csv(\"{}_{}.csv\".format(tg_id, year))\n",
    "        #df.to_excel(\"{}.xlsx\".format(tg_id))\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        monthly_min = df.groupby(df.time.dt.month)['{}'.format(tg_id)]\n",
    "        max_temp = monthly_min.max()\n",
    "        max_tempdf = pd.DataFrame(max_temp)\n",
    "        print(max_tempdf)\n",
    "        #max_tempdf.to_csv('{}_maxtemp_{}.csv'.format(tg_id, year))\n",
    "    else:\n",
    "        pass\n",
    "#print(out_sel)\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"\\n DONE PROCESSING..\")\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
